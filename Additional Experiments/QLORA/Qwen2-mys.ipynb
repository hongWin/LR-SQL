{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb645258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vipuser/miniconda3/envs/schema-R1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from src.open_r1.trl_main.trl.trainer import SFTTrainer\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "# from swanlab.integration.huggingface import SwanLabCallback\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import re\n",
    "# 该代码多卡SFT 设置 cuda visiable \n",
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ffe0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# file_path = \"training_prompt2.csv\"\n",
    "# model_path = \"/home/LLM/models/Qwen2.5-0.5B-Instruct\"\n",
    "# model_path = \"/home/LLM/models/Qwen2.5-0.5B-Instruct\"\n",
    "model_path = \"/home/model/para_Qwen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da936b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q\n",
    "# Check if GPU benefits from bfloat16\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    torch_dtype = torch.bfloat16\n",
    "else:\n",
    "    torch_dtype = torch.float16\n",
    "\n",
    "\n",
    "model_kwargs = dict(\n",
    "    attn_implementation=\"sdpa\",  # 注意力实现机制，可以使用flash_attention_2代替\n",
    "    torch_dtype=torch_dtype, # 使用的torch dtype类型，默认为自动\n",
    "    use_cache=False,  # 我们使用梯度检查点\n",
    "    device_map=\"auto\", # define model kwargs\n",
    ")\n",
    "\n",
    "model_kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=model_kwargs['torch_dtype'],\n",
    "    bnb_4bit_quant_storage=model_kwargs['torch_dtype'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9b32e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████| 4/4 [00:45<00:00, 11.49s/it]\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6243af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 1270.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 1082.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "['manufacturers', 'products', 'student', 'plays_games', 'sportsinfo', 'actor', 'entrepreneur', 'people', 'ref_hotel_star_ratings', 'ref_attraction_types', 'hotels', 'tourist_attractions', 'street_markets', 'shops', 'museums', 'royal_family', 'theme_parks', 'visits', 'photos', 'staff']\n",
      "['tourist_attraction_features', 'wrestler', 'elimination', 'business', 'category', 'checkin', 'neighbourhood', 'review', 'tip', 'ref_detention_type', 'ref_incident_type', 'addresses', 'students', 'teachers', 'assessment_notes', 'behavior_incident', 'detention']\n",
      "['student_addresses', 'students_in_detention', 'film', 'film_market_estimation', 'catalogs', 'catalog_structure', 'catalog_contents', 'catalog_contents_additional_attributes', 'routes', 'airports', 'stadium', 'game', 'injury_accident', 'physician', 'department', 'affiliated_with', 'trained_in', 'patient', 'nurse']\n",
      "['appointment', 'prescribes', 'block', 'room', 'on_call', 'stay', 'undergoes', 'buildings', 'office_locations', 'region', 'party', 'member', 'party_events', 'web_client_accelerator', 'accelerator_compatible_browser', 'investors', 'lots', 'transactions', 'sales', 'purchases', 'transactions_lots']\n",
      "['basketball_match', 'university', 'geographic', 'restaurant', 'location', 'follows', 'tweets', 'user_profiles', 'station', 'status', 'campuses', 'csu_fees', 'degrees', 'discipline_enrollments', 'enrollments', 'faculty', 'journalist', 'news_report', 'authors', 'authorship', 'manufacturer', 'furniture_manufacte', 'person', 'personfriend']\n",
      "['enzyme', 'medicine_enzyme_interaction', 'apartment_buildings', 'apartments', 'apartment_facilities', 'apartment_bookings', 'view_unit_status', 'channel', 'broadcast', 'broadcast_share', 'customer_master_index', 'cmi_cross_references', 'council_tax', 'business_rates', 'benefits_overpayments', 'parking_fines', 'rent_arrears', 'electoral_register', 'store', 'store_product', 'store_district', 'gas_station', 'station_company']\n",
      "['artwork', 'nomination', 'building', 'institution', 'protein', 'roller_coaster', 'country', 'services', 'events', 'participants_in_events', 'architect', 'bridge', 'mill', 'railway', 'train', 'railway_manage', 'publication', 'book', 'video_games', 'musical', 'locations', 'visitors', 'features', 'user', 'ref_address_types', 'market']\n",
      "['attribute_definitions', 'airlines', 'procedures', 'medication', 'companies', 'browser', 'ref_transaction_types', 'trip', 'weather', 'event', 'inst', 'papers', 'furniture', 'medicine', 'guests', 'program', 'product', 'district', 'company', 'festival_detail', 'participants', 'manager']\n",
      "172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 拆解训练集\n",
    "# 提供每次训练token数\n",
    "from tqdm import tqdm\n",
    "import copy \n",
    "import re\n",
    "#  1600 8   2200 6   2600 \n",
    "max_token = 1100\n",
    "#  保证特殊字符能被识别\n",
    "accept_toekn = max_token - 170\n",
    "#获取REF表数据\n",
    "tab_str = \"\"\n",
    "schema_slicing = []\n",
    "df = pd.read_csv(\"./dataset2/table_schema_Reference_cropped.csv\",encoding=\"utf-8\")\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    table_group = row['Reference_group']\n",
    "    tab_str_elder = copy.deepcopy(tab_str)\n",
    "    tab_str += table_group + \"\\n\"\n",
    "    check_token = tokenizer(f\"{tab_str}\", add_special_tokens=False)\n",
    "    if len(check_token[\"input_ids\"]) > accept_toekn:\n",
    "        schema_slicing.append(tab_str_elder)\n",
    "        tab_str = table_group + \"\\n\"\n",
    "\n",
    "    \n",
    "print(len(schema_slicing))\n",
    "\n",
    "# print(ReF_group[5])\n",
    "# print(\"#############################\")\n",
    "# print(ReF_group[6])\n",
    "\n",
    "\n",
    "#获取noREF表数据\n",
    "df = pd.read_csv(\"./dataset2/table_schema_noReference_cropped.csv\",encoding=\"utf-8\")\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    table_group = row['noReference_group']\n",
    "    tab_str_elder = copy.deepcopy(tab_str)\n",
    "    tab_str += table_group + \"\\n\"\n",
    "    check_token = tokenizer(f\"{tab_str}\", add_special_tokens=False)\n",
    "    if len(check_token[\"input_ids\"]) > accept_toekn:\n",
    "#         print(\"+++++++++++\")\n",
    "        schema_slicing.append(tab_str_elder)\n",
    "        tab_str = table_group + \"\\n\"\n",
    "        \n",
    "        \n",
    "if len(tab_str) > 0:\n",
    "    schema_slicing.append(tab_str)\n",
    "\n",
    "print(len(schema_slicing))\n",
    "# print(schema_slicing[6])\n",
    "# print(\"#############################\")\n",
    "# print(schema_slicing[7])\n",
    "# print(schema_slicing[8])\n",
    "\n",
    "create_table_pattern = re.compile(r'CREATE TABLE `[^`]+` \\([^;]+\\);')\n",
    "table_name_group = []\n",
    "test_total = set()\n",
    "count = 0\n",
    "for piece in schema_slicing:\n",
    "    create_table_statements = create_table_pattern.findall(piece)\n",
    "    temp_list = []\n",
    "    for table in create_table_statements:\n",
    "        table_name = re.search(r\"CREATE TABLE `([^`]+)`\", table).group(1)\n",
    "        temp_list.append(table_name.lower())\n",
    "        test_total.add(table_name.lower())\n",
    "        count+=1\n",
    "    print(temp_list)\n",
    "    table_name_group.append(temp_list)\n",
    "# print(count)\n",
    "print(len(test_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2bc9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_prompt(schema_pad):\n",
    "    return f\" I want you to act as a relation extraction robot for a sample SQL table. You only need to return the tables related to the user's input question. Below are instructions describing the relationship between tables. Please write a response that appropriately completes the request. \\n##instruction:{schema_pad}\"\n",
    "\n",
    "def make_user_prompt(question_pad, selected_table_pad):\n",
    "    return f\"{question_pad}######selected_table: {selected_table_pad}.\"\n",
    "\n",
    "def make_reponse(answer_pad):\n",
    "    return f\"```Reference Table\\n-- Tables: {answer_pad};\\n```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59a735a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conversation(schema_pad, question_pad, selected_table_pad,answer_pad):\n",
    "    conversation = []\n",
    "    conversation0 = {}\n",
    "    conversation1 = {}\n",
    "    conversation2 = {}\n",
    "    system_prompt = make_system_prompt(schema_pad)\n",
    "    user_prompt = make_user_prompt(question_pad, selected_table_pad)\n",
    "    assistance_prompt = make_reponse(answer_pad)\n",
    "    conversation0[\"role\"] = \"system\"\n",
    "    conversation0[\"content\"] = system_prompt\n",
    "    conversation1[\"role\"] = \"user\"\n",
    "    conversation1[\"content\"] = user_prompt + \"\\n\"\n",
    "    conversation2[\"role\"] = \"assistant\"\n",
    "    conversation2[\"content\"] = assistance_prompt\n",
    "    conversation.append(conversation0)\n",
    "    conversation.append(conversation1)\n",
    "    conversation.append(conversation2)\n",
    "    all_info = system_prompt + user_prompt + assistance_prompt\n",
    "#     print(conversation2[\"content\"])\n",
    "    return conversation, all_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d97cf33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dataset_template(schema_pad,question_pad,selected_table_pad,answer_pad):\n",
    "     message = {\n",
    "                \"instruction\": f\" I want you to act as a relation extraction robot for a sample SQL table. You only need to return the tables related to the user's input question. Below are instructions describing the relationship between tables. Please write a response that appropriately completes the request. \\n##instruction:{schema_pad}\",\n",
    "                \"input\": f\"{question_pad}######selected_table: {selected_table_pad}.\",\n",
    "                \"output\": f\"```Reference Table\\n-- Tables: {answer_pad};\\n```\",\n",
    "            }\n",
    "     return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6741a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20087\n",
      "20087\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset2/full_finetuning_dataset_cropped.csv\",encoding=\"utf-8\")\n",
    "outer_index = 0\n",
    "message_group = []\n",
    "trans_data = {}\n",
    "check1 = 0\n",
    "for i in range(len(df['db_id'])):\n",
    "    question = df['question'][i]\n",
    "    query = df['query'][i]\n",
    "    correct_table = df['correct_tables'][i]\n",
    "    correct_table_list = correct_table.split(\", \")\n",
    "    dict_target_table_slice = {}\n",
    "    for target_table in correct_table_list:\n",
    "        for index, table_name_slicing in enumerate(table_name_group): \n",
    "            if target_table.lower() in table_name_slicing:\n",
    "                dict_target_table_slice[target_table] = index\n",
    "                break    \n",
    "#     if  len(dict_target_table_slice) != len(correct_table_list):\n",
    "#         print(f\"error--{outer_index}----\",list(dict_target_table_slice.keys()),\"=====\",correct_table_list)\n",
    "#     outer_index += 1     \n",
    "#     基于定位构建两条数据集: 一条顺序 一条判断\n",
    "#     顺序\n",
    "    sorted_relation = sorted(dict_target_table_slice.items(), key=lambda x: x[1])\n",
    "    selected_table_list = []\n",
    "    for index, piece in enumerate(schema_slicing):\n",
    "        this_selected = []\n",
    "        for key, value in sorted_relation:\n",
    "            if index == value:\n",
    "                this_selected.append(key)\n",
    "#          给与选择提示\n",
    "        message = None\n",
    "        if len(selected_table_list) > 0:\n",
    "            selected_table_str = ', '.join(selected_table_list)\n",
    "            if len(this_selected) == 0:\n",
    "                message = fill_dataset_template(piece,question,selected_table_str,\"#None#\")\n",
    "                conversation, all_info = make_conversation(piece,question,selected_table_str,\"#None#\")\n",
    "            else:\n",
    "                this_selected_str = ', '.join(this_selected)\n",
    "                message = fill_dataset_template(piece,question,selected_table_str,this_selected_str)\n",
    "                conversation, all_info = make_conversation(piece,question,selected_table_str,this_selected_str)\n",
    "        if message is not None:\n",
    "            check1 += 1\n",
    "            message_group.append(conversation)\n",
    "            token_len = len(tokenizer(all_info, add_special_tokens=False)[\"input_ids\"])\n",
    "            if  token_len >  max_token:\n",
    "                max_token = token_len\n",
    "#          不给与选择提示 + 顺序决策   \n",
    "        if len(this_selected) == 0:\n",
    "            conversation, all_info = make_conversation(piece,question,\"None\",\"#None#\")\n",
    "            message = fill_dataset_template(piece,question,\"None\",\"#None#\")\n",
    "        else:\n",
    "            this_selected_str = ', '.join(this_selected)\n",
    "            message = fill_dataset_template(piece,question,\"None\",this_selected_str)\n",
    "            conversation, all_info = make_conversation(piece,question,\"None\",this_selected_str)\n",
    "        \n",
    "        if len(this_selected) > 0:\n",
    "            for item in this_selected:\n",
    "                selected_table_list.append(item)\n",
    "                \n",
    "        message_group.append(conversation)\n",
    "        check1 += 1\n",
    "        \n",
    "print(len(message_group))\n",
    "trans_data[\"messages\"] = message_group\n",
    "print(check1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de9a69fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n"
     ]
    }
   ],
   "source": [
    "print(max_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "835adf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20087\n",
      "{'messages': [{'content': \" I want you to act as a relation extraction robot for a sample SQL table. You only need to return the tables related to the user's input question. Below are instructions describing the relationship between tables. Please write a response that appropriately completes the request. \\n##instruction:CREATE TABLE `Manufacturers` (\\r\\n  Code INTEGER,\\r\\n  Name VARCHAR(255),\\r\\n  Headquarter VARCHAR(255),\\r\\n  Founder VARCHAR(255),\\r\\n  Revenue REAL\\r\\n);\\nCREATE TABLE `Products` (\\r\\n  Code INTEGER,\\r\\n  Name VARCHAR(255),\\r\\n  Price DECIMAL,\\r\\n  Manufacturer INTEGER REFERENCES Manufacturers(Code)\\r\\n);\\nCREATE TABLE `Student` (\\r\\n  StuID INTEGER,\\r\\n  LName VARCHAR(12),\\r\\n  Fname VARCHAR(12),\\r\\n  Age INTEGER,\\r\\n  Sex VARCHAR(1),\\r\\n  Major INTEGER,\\r\\n  Advisor INTEGER,\\r\\n  city_code VARCHAR(3)\\r\\n);\\nCREATE TABLE `Plays_Games` (\\r\\n  StuID INTEGER REFERENCES Student(StuID),\\r\\n  GameID INTEGER REFERENCES Video_Games(GameID),\\r\\n  Hours_Played INTEGER\\r\\n);\\nCREATE TABLE `SportsInfo` (\\r\\n  StuID INTEGER REFERENCES Student(StuID),\\r\\n  SportName VARCHAR(32),\\r\\n  HoursPerWeek INTEGER,\\r\\n  GamesPlayed INTEGER,\\r\\n  OnScholarship VARCHAR(1)\\r\\n);\\nCREATE TABLE `actor` (\\r\\n  Actor_ID INT PRIMARY KEY,\\r\\n  Name TEXT,\\r\\n  Musical_ID INT REFERENCES actor(Actor_ID),\\r\\n  Character TEXT,\\r\\n  Duration TEXT,\\r\\n  age INT\\r\\n);\\nCREATE TABLE `entrepreneur` (\\r\\n  Entrepreneur_ID INT PRIMARY KEY,\\r\\n  People_ID INT REFERENCES people(People_ID),\\r\\n  Company TEXT,\\r\\n  Money_Requested REAL,\\r\\n  Investor TEXT\\r\\n);\\nCREATE TABLE `people` (\\r\\n  People_ID INT PRIMARY KEY,\\r\\n  Name TEXT,\\r\\n  Height REAL,\\r\\n  Weight REAL,\\r\\n  Date_of_Birth TEXT\\r\\n);\\nCREATE TABLE `Ref_Hotel_Star_Ratings` (\\r\\n  star_rating_code CHAR(15) PRIMARY KEY,\\r\\n  star_rating_description VARCHAR(80)\\r\\n);\\nCREATE TABLE `Ref_Attraction_Types` (\\r\\n  Attraction_Type_Code CHAR(15) PRIMARY KEY,\\r\\n  Attraction_Type_Description VARCHAR(255)\\r\\n);\\nCREATE TABLE `Hotels` (\\r\\n  hotel_id INTEGER,\\r\\n  star_rating_code CHAR(15) REFERENCES Ref_Hotel_Star_Ratings(star_rating_code),\\r\\n  pets_allowed_yn CHAR(1),\\r\\n  price_range REAL,\\r\\n  other_hotel_details VARCHAR(255)\\r\\n);\\nCREATE TABLE `Tourist_Attractions` (\\r\\n  Tourist_Attraction_ID INTEGER,\\r\\n  Attraction_Type_Code CHAR(15) REFERENCES Ref_Attraction_Types(Attraction_Type_Code),\\r\\n  Location_ID INTEGER REFERENCES Locations(Location_ID),\\r\\n  How_to_Get_There VARCHAR(255),\\r\\n  Name VARCHAR(255),\\r\\n  Description VARCHAR(255),\\r\\n  Opening_Hours VARCHAR(255),\\r\\n  Other_Details VARCHAR(255)\\r\\n);\\nCREATE TABLE `Street_Markets` (\\r\\n  Market_ID INTEGER REFERENCES Tourist_Attractions(Tourist_Attraction_ID),\\r\\n  Market_Details VARCHAR(255)\\r\\n);\\nCREATE TABLE `Shops` (\\r\\n  Shop_ID INTEGER REFERENCES Tourist_Attractions(Tourist_Attraction_ID),\\r\\n  Shop_Details VARCHAR(255)\\r\\n);\\nCREATE TABLE `Museums` (\\r\\n  Museum_ID INTEGER REFERENCES Tourist_Attractions(Tourist_Attraction_ID),\\r\\n  Museum_Details VARCHAR(255)\\r\\n);\\nCREATE TABLE `Royal_Family` (\\r\\n  Royal_Family_ID INTEGER REFERENCES Tourist_Attractions(Tourist_Attraction_ID),\\r\\n  Royal_Family_Details VARCHAR(255)\\r\\n);\\nCREATE TABLE `Theme_Parks` (\\r\\n  Theme_Park_ID INTEGER REFERENCES Tourist_Attractions(Tourist_Attraction_ID),\\r\\n  Theme_Park_Details VARCHAR(255)\\r\\n);\\nCREATE TABLE `Visits` (\\r\\n  Visit_ID INTEGER,\\r\\n  Tourist_Attraction_ID INTEGER REFERENCES Tourist_Attractions(Tourist_Attraction_ID),\\r\\n  Tourist_ID INTEGER REFERENCES Visitors(Tourist_ID),\\r\\n  Visit_Date DATETIME,\\r\\n  Visit_Details VARCHAR(40)\\r\\n);\\nCREATE TABLE `Photos` (\\r\\n  Photo_ID INTEGER,\\r\\n  Tourist_Attraction_ID INTEGER REFERENCES Tourist_Attractions(Tourist_Attraction_ID),\\r\\n  Name VARCHAR(255),\\r\\n  Description VARCHAR(255),\\r\\n  Filename VARCHAR(255),\\r\\n  Other_Details VARCHAR(255)\\r\\n);\\nCREATE TABLE `Staff` (\\r\\n  Staff_ID INTEGER,\\r\\n  Tourist_Attraction_ID INTEGER REFERENCES Tourist_Attractions(Tourist_Attraction_ID),\\r\\n  Name VARCHAR(40),\\r\\n  Other_Details VARCHAR(255)\\r\\n);\\n\", 'role': 'system'}, {'content': 'Find the total revenue of companies of each founder.######selected_table: None.\\n', 'role': 'user'}, {'content': '```Reference Table\\n-- Tables: manufacturers;\\n```', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "trans_data = pd.DataFrame(trans_data)\n",
    "trans_data = Dataset.from_pandas(trans_data,split=\"train\")\n",
    "print(len(trans_data))\n",
    "for sample in trans_data:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b7b6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fill_dataset_template(schema_pad,question_pad,selected_table_pad,answer_pad):\n",
    "#      message = {\n",
    "#                 \"instruction\": f\" I want you to act as a relation extraction robot for a sample SQL table. You only need to return the tables related to the user's input question. Below are instructions describing the relationship between tables. Please write a response that appropriately completes the request. \\n##instruction:{schema_pad}\",\n",
    "#                 \"input\": f\"{question_pad}######selected_table: {selected_table_pad}.\",\n",
    "#                 \"output\": f\"```Reference Table\\n-- Tables: {answer_pad};\\n```\",\n",
    "#             }\n",
    "#      return message\n",
    "#  #None#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "124015b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"./dataset2/full_finetuning_dataset_cropped.csv\",encoding=\"utf-8\")\n",
    "# outer_index = 0\n",
    "# message_group = []\n",
    "# check2 = 0\n",
    "# for i in range(len(df['db_id'])):\n",
    "#     question = df['question'][i]\n",
    "#     query = df['query'][i]\n",
    "#     correct_table = df['correct_tables'][i]\n",
    "#     correct_table_list = correct_table.split(\", \")\n",
    "#     dict_target_table_slice = {}\n",
    "#     for target_table in correct_table_list:\n",
    "#         for index, table_name_slicing in enumerate(table_name_group): \n",
    "#             if target_table.lower() in table_name_slicing:\n",
    "#                 dict_target_table_slice[target_table] = index\n",
    "#                 break    \n",
    "# #     if  len(dict_target_table_slice) != len(correct_table_list):\n",
    "# #         print(f\"error--{outer_index}----\",list(dict_target_table_slice.keys()),\"=====\",correct_table_list)\n",
    "# #     outer_index += 1     \n",
    "# #     基于定位构建两条数据集: 一条顺序 一条判断\n",
    "# #     顺序\n",
    "#     sorted_relation = sorted(dict_target_table_slice.items(), key=lambda x: x[1])\n",
    "#     selected_table_list = []\n",
    "#     for index, piece in enumerate(schema_slicing):\n",
    "#         this_selected = []\n",
    "#         for key, value in sorted_relation:\n",
    "#             if index == value:\n",
    "#                 this_selected.append(key)\n",
    "# #          给与选择提示\n",
    "#         message = None\n",
    "#         if len(selected_table_list) > 0:\n",
    "#             selected_table_str = ', '.join(selected_table_list)\n",
    "#             if len(this_selected) == 0:\n",
    "#                 message = fill_dataset_template(piece,question,selected_table_str,\"#None#\")\n",
    "#             else:\n",
    "#                 this_selected_str = ', '.join(this_selected)\n",
    "#                 message = fill_dataset_template(piece,question,selected_table_str,this_selected_str)\n",
    "#         if message is not None:\n",
    "#             check2 += 1\n",
    "#             message_group.append(message)\n",
    "# #          不给与选择提示 + 顺序决策   \n",
    "#         if len(this_selected) == 0:\n",
    "#             message = fill_dataset_template(piece,question,\"None\",\"#None#\")\n",
    "#         else:\n",
    "#             this_selected_str = ', '.join(this_selected)\n",
    "#             message = fill_dataset_template(piece,question,\"None\",this_selected_str)\n",
    "        \n",
    "#         if len(this_selected) > 0:\n",
    "#             for item in this_selected:\n",
    "#                 selected_table_list.append(item)\n",
    "                \n",
    "#         message_group.append(message)\n",
    "#         check2 += 1\n",
    "        \n",
    "# print(len(message_group))\n",
    "# #     判断\n",
    "# print(check2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c532dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"SFT_Q_S2\"\n",
    "num_train_epochs = 3\n",
    "bf16 = True\n",
    "overwrite_output_dir = True\n",
    "per_device_train_batch_size = 2\n",
    "gradient_accumulation_steps = 16\n",
    "gradient_checkpointing = True\n",
    "evaluation_strategy = \"steps\"\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 0.01\n",
    "lr_scheduler_type = \"cosine\"\n",
    "warmup_ratio = 0.01\n",
    "max_grad_norm = 0.3\n",
    "group_by_length = True\n",
    "auto_find_batch_size = False\n",
    "save_steps = 50\n",
    "logging_steps = 50\n",
    "load_best_model_at_end= False\n",
    "packing = False\n",
    "save_total_limit=1\n",
    "neftune_noise_alpha=5\n",
    "# report_to=\"wandb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00c465eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_r = 64\n",
    "lora_alpha = 32\n",
    "lora_dropout = 0.1\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj'],\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a440fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "# from swanlab.integration.huggingface import SwanLabCallback\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    load_best_model_at_end=load_best_model_at_end,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "#     evaluation_strategy=evaluation_strategy,\n",
    "    max_grad_norm = max_grad_norm,\n",
    "    auto_find_batch_size = auto_find_batch_size,\n",
    "    save_total_limit = save_total_limit,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    bf16=bf16,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"none\",\n",
    "    neftune_noise_alpha= neftune_noise_alpha\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd71e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4d2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swanlab_callback = SwanLabCallback(\n",
    "#     project=\"Qwen2.5_1.5B_GRPO_steer_CoT\",\n",
    "#     experiment_name=\"Qwen2.5_1.5B_GRPO_steer_CoT\",\n",
    "#     description=\"Qwen2.5_1.5B_GRPO_steer_CoT\",\n",
    "#     config={\n",
    "#         \"model\": \"Qwen2.5-1.5B\",\n",
    "#         \"dataset\": \"steer_CoT\",\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe872266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train dataset to ChatML: 100%|███████████████████████████████████████████████████| 20087/20087 [00:00<00:00, 25125.36 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████████████████████████████████████████| 20087/20087 [00:01<00:00, 10803.77 examples/s]\n",
      "Tokenizing train dataset: 100%|███████████████████████████████████████████████████████████████| 20087/20087 [00:37<00:00, 533.00 examples/s]\n",
      "Truncating train dataset: 100%|█████████████████████████████████████████████████████████████| 20087/20087 [00:00<00:00, 38712.98 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model= model,\n",
    "    train_dataset=trans_data,\n",
    "    peft_config = peft_config,\n",
    "    args=training_arguments,\n",
    "#     callbacks=[swanlab_callback],\n",
    "#     params_mask = params_mask\n",
    ")\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342afece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='1881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   4/1881 00:23 < 6:04:25, 0.09 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6f63655",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d215e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件复制成功！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    " \n",
    "# 源文件路径\n",
    "tokenizer_config_path = os.path.join(model_path, \"tokenizer_config.json\")\n",
    "tokenizer_path = os.path.join(model_path, \"tokenizer.json\")\n",
    "  \n",
    "# 确保目标目录存在\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    " \n",
    "# 复制文件\n",
    "try:\n",
    "    shutil.copy2(tokenizer_config_path, output_dir)\n",
    "    shutil.copy2(tokenizer_path, output_dir)\n",
    "    print(\"文件复制成功！\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"错误：找不到源文件 - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"发生错误：{e}\")# inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08275b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60772ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use_my_SFTtrainer 自己的trl库源码\n",
    "# processing_class, train_dataset = trainer.get_dataset()\n",
    "# print(train_dataset)\n",
    "# print(processing_class)\n",
    "# # completions_text = self.processing_class.batch_decode(completion_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c13d702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "# print(type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac533a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'aplaca', 'num_turns': 2, 'text': \"<|im_start|>system\\nYou are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\\n...\\n</think>\\n<answer>\\n...\\n</answer><|im_end|>\\n<|im_start|>user\\nDescribe a process of making crepes.\\n<|im_end|>\\n<|im_start|>assistant\\nMaking crepes is an easy and delicious process! Here are step-by-step instructions on how to make them:\\n\\n1. Assemble your ingredients. For basic crepes, you'll need: 1 cup all-purpose flour, 2 eggs, 1/2 cup milk, 1/2 cup water, 1/4 teaspoon salt, and 2 tablespoons melted butter.\\n\\n2. Mix the batter: In a large mixing bowl, whisk together the flour and the eggs. Gradually add the milk and water, stirring constantly to ensure that there are no lumps. Add salt and melted butter, and mix well.\\n\\n3. Let the batter rest: If you can, let the batter sit for an hour or so. This will help the flour to absorb the liquid and make the crepes more tender.\\n\\n4. Heat your pan: Preheat a non-stick pan over medium heat. Lightly butter the pan or use cooking spray to prevent the crepes from sticking.\\n\\n5. Pour the batter: Using a ladle or a measuring cup, pour a small amount of batter (about 1/4 cup) onto the center of the pan. Immediately tilt the pan in a circular motion to spread the batter evenly and thinly over the bottom of the pan.\\n\\n6. Cook the crepe: Cook the crepe for 1-2 minutes until the bottom is lightly golden. Carefully loosen the edges with a spatula and flip the crepe over to cook the other side for another minute.\\n\\n7. Remove and repeat: Gently slide the crepe onto a plate, and then repeat the process with the remaining batter. Remember to re-butter the pan between each crepe if necessary.\\n\\n8. Fill and serve: Fill your cooked crepes with your desired filling, such as fresh fruit, whipped cream, Nutella, or ham and cheese. Roll or fold, and serve immediately. Enjoy!<|im_end|>\\n\", 'input_ids': [151644, 8948, 198, 2610, 525, 264, 10950, 15235, 21388, 429, 5707, 1632, 5504, 1497, 291, 323, 11682, 14507, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 438, 458, 5306, 1615, 76728, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 39533, 304, 279, 2701, 3561, 25, 366, 26865, 397, 9338, 522, 26865, 397, 27, 9217, 397, 9338, 522, 9217, 29, 151645, 198, 151644, 872, 198, 74785, 264, 1882, 315, 3259, 1884, 20352, 624, 151645, 198, 151644, 77091, 198, 42246, 1884, 20352, 374, 458, 4135, 323, 17923, 1882, 0, 5692, 525, 3019, 14319, 29208, 11221, 389, 1246, 311, 1281, 1105, 1447, 16, 13, 1634, 15790, 697, 13966, 13, 1752, 6770, 1884, 20352, 11, 498, 3278, 1184, 25, 220, 16, 10525, 678, 58238, 19828, 11, 220, 17, 18805, 11, 220, 16, 14, 17, 10525, 14074, 11, 220, 16, 14, 17, 10525, 3015, 11, 220, 16, 14, 19, 41284, 12021, 11, 323, 220, 17, 55488, 49359, 14100, 382, 17, 13, 19219, 279, 8745, 25, 758, 264, 3460, 26792, 19212, 11, 40659, 3786, 279, 19828, 323, 279, 18805, 13, 21794, 1832, 912, 279, 14074, 323, 3015, 11, 53954, 14971, 311, 5978, 429, 1052, 525, 902, 326, 11793, 13, 2691, 12021, 323, 49359, 14100, 11, 323, 6514, 1632, 382, 18, 13, 6771, 279, 8745, 2732, 25, 1416, 498, 646, 11, 1077, 279, 8745, 2444, 369, 458, 6460, 476, 773, 13, 1096, 686, 1492, 279, 19828, 311, 34306, 279, 14473, 323, 1281, 279, 1884, 20352, 803, 27582, 382, 19, 13, 26070, 697, 7215, 25, 4968, 19963, 264, 2477, 5477, 865, 7215, 916, 11051, 8628, 13, 8658, 398, 14100, 279, 7215, 476, 990, 17233, 22899, 311, 5358, 279, 1884, 20352, 504, 36972, 382, 20, 13, 25968, 279, 8745, 25, 12091, 264, 57625, 273, 476, 264, 28990, 10525, 11, 4914, 264, 2613, 3311, 315, 8745, 320, 9096, 220, 16, 14, 19, 10525, 8, 8630, 279, 4126, 315, 279, 7215, 13, 68252, 36200, 279, 7215, 304, 264, 26931, 11379, 311, 8865, 279, 8745, 41047, 323, 98431, 916, 279, 5622, 315, 279, 7215, 382, 21, 13, 12514, 279, 1884, 375, 25, 12514, 279, 1884, 375, 369, 220, 16, 12, 17, 4420, 3080, 279, 5622, 374, 33404, 20748, 13, 10627, 3641, 82742, 279, 12822, 448, 264, 62883, 5607, 323, 18287, 279, 1884, 375, 916, 311, 4296, 279, 1008, 3108, 369, 2441, 9383, 382, 22, 13, 10783, 323, 13153, 25, 479, 4402, 14983, 279, 1884, 375, 8630, 264, 11968, 11, 323, 1221, 13153, 279, 1882, 448, 279, 9664, 8745, 13, 19881, 311, 312, 1455, 6207, 279, 7215, 1948, 1817, 1884, 375, 421, 5871, 382, 23, 13, 21979, 323, 8683, 25, 21979, 697, 29105, 1884, 20352, 448, 697, 12685, 21274, 11, 1741, 438, 7722, 13779, 11, 63257, 12644, 11, 18372, 6842, 11, 476, 13515, 323, 17163, 13, 14686, 476, 11555, 11, 323, 8683, 7069, 13, 22656, 0, 151645, 198, 151645], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# for i in train_dataset:\n",
    "#     print(i)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f432c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: swanlab version 0.5.5 is available!  Upgrade: `pip install -U swanlab`    \n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Tracking run with swanlab version 0.5.4                                   \n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Run data will be saved locally in \u001b[35m\u001b[1m/home/LLM/code/open-r1-main/swanlog/run-20250409_133541-a3b1799d\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 👋 Hi \u001b[1m\u001b[39mwinhong\u001b[0m\u001b[0m, welcome to swanlab!\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Syncing run \u001b[33mQwen2.5-1.5B_Full_Aplaca_test_GRPO_SFT\u001b[0m to the cloud\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 🏠 View project at \u001b[34m\u001b[4mhttps://swanlab.cn/@winhong/Qwen2.5-1.5B_Full_Aplaca_test_GRPO_SFT\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://swanlab.cn/@winhong/Qwen2.5-1.5B_Full_Aplaca_test_GRPO_SFT/runs/wjtnv2yua7qkfkwpa4cmg\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/transformers/trainer.py:2463\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2461\u001b[39m model.zero_grad()\n\u001b[32m   2462\u001b[39m grad_norm: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2463\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallback_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.eval_on_start:\n\u001b[32m   2466\u001b[39m     \u001b[38;5;28mself\u001b[39m._evaluate(trial, ignore_keys_for_eval, skip_scheduler=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/transformers/trainer_callback.py:506\u001b[39m, in \u001b[36mCallbackHandler.on_train_begin\u001b[39m\u001b[34m(self, args, state, control)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_train_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[32m    505\u001b[39m     control.should_training_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_train_begin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/transformers/trainer_callback.py:556\u001b[39m, in \u001b[36mCallbackHandler.call_event\u001b[39m\u001b[34m(self, event, args, state, control, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, **kwargs):\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         result = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[32m    569\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/swanlab/integration/transformers.py:215\u001b[39m, in \u001b[36mSwanLabCallback.on_train_begin\u001b[39m\u001b[34m(self, args, state, control, model, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_train_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, state, control, model=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._initialized:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/swanlab/integration/transformers.py:167\u001b[39m, in \u001b[36mSwanLabCallback.setup\u001b[39m\u001b[34m(self, args, state, model, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._swanlab.get_run() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# ATTENTION: little differents in transformers\u001b[39;00m\n\u001b[32m    166\u001b[39m     init_args.update(\u001b[38;5;28mself\u001b[39m._swanlab_init)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_swanlab\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# show transformers logo!\u001b[39;00m\n\u001b[32m    171\u001b[39m \u001b[38;5;28mself\u001b[39m._swanlab.config[\u001b[33m\"\u001b[39m\u001b[33mFRAMEWORK\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m🤗transformers\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/swanlab/data/sdk.py:201\u001b[39m, in \u001b[36mSwanLabInitializer.init\u001b[39m\u001b[34m(self, project, workspace, experiment_name, description, config, logdir, mode, load, public, callbacks, settings, **kwargs)\u001b[39m\n\u001b[32m    198\u001b[39m config = _init_config(config)\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ---------------------------------- 实例化实验 ----------------------------------\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[38;5;66;03m# 注册实验\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m run = \u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_level\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlog_level\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minfo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_num\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexp_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m run\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/swanlab/data/run/__init__.py:15\u001b[39m, in \u001b[36mregister\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mregister\u001b[39m(*args, **kwargs) -> SwanLabRun:\n\u001b[32m     14\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"注册并实例化SwanLabRun类\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     run = \u001b[43mSwanLabRun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m run\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/swanlab/data/run/main.py:121\u001b[39m, in \u001b[36mSwanLabRun.__init__\u001b[39m\u001b[34m(self, project_name, experiment_name, description, run_config, log_level, exp_num, operator)\u001b[39m\n\u001b[32m    118\u001b[39m run = \u001b[38;5;28mself\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# ---------------------------------- 初始化完成 ----------------------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__operator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# 执行__save，必须在on_run之后，因为on_run之前部分的信息还没完全初始化\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33m_SwanLabConfig__save\u001b[39m\u001b[33m\"\u001b[39m)()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/swanlab/data/run/helper.py:109\u001b[39m, in \u001b[36mSwanLabRunOperator.on_run\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__run_all\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_run\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     try_send_webhook()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/swanlab/data/run/helper.py:59\u001b[39m, in \u001b[36mSwanLabRunOperator.__run_all\u001b[39m\u001b[34m(self, method, *args, **kwargs)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__run_all\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/swanlab/data/run/helper.py:59\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__run_all\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {name: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name, callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks.items()}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/swanlab/data/callbacker/cloud.py:141\u001b[39m, in \u001b[36mCloudRunCallback.on_run\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# 在Jupyter Notebook环境下，显示按钮\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m in_jupyter():\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[43mshow_button_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_url\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/swanlab/data/callbacker/cloud.py:322\u001b[39m, in \u001b[36mshow_button_html\u001b[39m\u001b[34m(experiment_url)\u001b[39m\n\u001b[32m    245\u001b[39m         js_code = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[33m        <script>\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[33m            function showIframe() \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    251\u001b[39m \u001b[33m        </script>\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    254\u001b[39m         total_h5 = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[33m<!DOCTYPE html>\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[33m<html lang=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33men\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[33m        28.2309 11.8938Z\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m fill=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhite\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m /> </svg> Display SwanLab Board </button> <br> <div \u001b[39m\n\u001b[32m    320\u001b[39m \u001b[33m        id=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33miframeContainer\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m></div> </body> </html>\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHTML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_h5\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    324\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/IPython/core/display_functions.py:285\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[39m\n\u001b[32m    282\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[32m    283\u001b[39m             \u001b[38;5;66;03m# kwarg-specified metadata gets precedence\u001b[39;00m\n\u001b[32m    284\u001b[39m             _merge(md_dict, metadata)\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m         \u001b[43mpublish_display_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmd_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m display_id:\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DisplayHandle(display_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/IPython/core/display_functions.py:73\u001b[39m, in \u001b[36mpublish_display_data\u001b[39m\u001b[34m(data, metadata, transient, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transient:\n\u001b[32m     71\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mtransient\u001b[39m\u001b[33m'\u001b[39m] = transient\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mdisplay_pub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/ipykernel/zmqshell.py:103\u001b[39m, in \u001b[36mZMQDisplayPublisher.publish\u001b[39m\u001b[34m(self, data, metadata, transient, update)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish\u001b[39m(\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     83\u001b[39m     data,\n\u001b[32m   (...)\u001b[39m\u001b[32m     86\u001b[39m     update=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     87\u001b[39m ):\n\u001b[32m     88\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Publish a display-data message\u001b[39;00m\n\u001b[32m     89\u001b[39m \n\u001b[32m     90\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m \u001b[33;03m        If True, send an update_display_data message instead of display_data.\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flush_streams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    105\u001b[39m         metadata = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/ipykernel/zmqshell.py:66\u001b[39m, in \u001b[36mZMQDisplayPublisher._flush_streams\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_flush_streams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     65\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     sys.stderr.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/site-packages/ipykernel/iostream.py:609\u001b[39m, in \u001b[36mOutStream.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    607\u001b[39m     \u001b[38;5;28mself\u001b[39m.pub_thread.schedule(evt.set)\n\u001b[32m    608\u001b[39m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    610\u001b[39m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[32m    611\u001b[39m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[32m    612\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIOStream.flush timed out\u001b[39m\u001b[33m\"\u001b[39m, file=sys.__stderr__)\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vipuser/miniconda3/envs/openr1/lib/python3.11/threading.py:331\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    333\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56445f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(\"./\", \"/home/LLM/models/SFT_model/Qwen_1.5B_GRPO_test\")\n",
    "trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfac360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schema-R1",
   "language": "python",
   "name": "schema-r1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
